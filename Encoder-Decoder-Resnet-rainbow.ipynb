{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "import os\n",
    "import random\n",
    "import janestreet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Seed(SEED=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)  \n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True \n",
    "\n",
    "Seed(SEED=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/chencheng/kaggle/jane-street-market-prediction/'\n",
    "DATA = pd.read_csv(\"{}train.csv\".format(DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = DATA[DATA.weight > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fill_NaN(df, begin_date=86):\n",
    "    assert begin_date >= 1, \"begin_date must be larger than 1.\"\n",
    "    data = pd.DataFrame()\n",
    "    while len(df[df.date == begin_date]) > 0:\n",
    "        #print(begin_date)\n",
    "        temp = df[df.date == begin_date]\n",
    "        temp.fillna(df[df.date == begin_date-1].mean(), inplace=True)\n",
    "        data = data.append(temp)\n",
    "        begin_date += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Fill_NaN(DATA)\n",
    "DATA = DATA[DATA.date > 85].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../model_02_18/DATA.pkl\",\"wb\") as file:\n",
    "    pickle.dump(DATA, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_standardize_zscore(df, mean=None, std=None):\n",
    "    if mean is not None and std is not None:\n",
    "        return (df - mean) / std\n",
    "    else:\n",
    "        std = df.std()\n",
    "        assert (std != 0).any(), \"series is constant\"\n",
    "        mean = df.mean()\n",
    "        return (df - mean) / std, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA['feature_41_42_43'] = DATA['feature_41'] + DATA['feature_42'] + DATA['feature_43']\n",
    "DATA['feature_1_2'] = DATA['feature_1'] / (DATA['feature_2'] + 1e-5)\n",
    "DATA['feature_41_42_43'], feature_41_42_43_mean, feature_41_42_43_std = ds_standardize_zscore(DATA['feature_41_42_43'])\n",
    "DATA['feature_1_2'], feature_1_2_mean, feature_1_2_std = ds_standardize_zscore(DATA['feature_1_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_cols = [c for c in DATA.columns if 'feature' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../model_02_18/f_mean.npy', DATA[fea_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def mpPDF(var,q,pts):\n",
    "    # Marcenko-Pastur pdf\n",
    "    # q=T/N\n",
    "    eMin, eMax = var*(1-(1./q)**.5)**2, var*(1+(1./q)**.5)**2\n",
    "    eVal = np.linspace(eMin,eMax,pts)\n",
    "    pdf = q/(2*np.pi*var*eVal)*((eMax-eVal)*(eVal-eMin))**.5\n",
    "    pdf = pd.Series(pdf.reshape(-1,), index=eVal.reshape(-1,))\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def getPCA(matrix):\n",
    "    # Get eVal,eVec from a Hermitian matrix\n",
    "    eVal,eVec = np.linalg.eigh(matrix)\n",
    "    indices=eVal.argsort()[::-1] # arguments for sorting eVal desc\n",
    "    eVal,eVec=eVal[indices],eVec[:,indices]\n",
    "    eVal=np.diagflat(eVal)\n",
    "    return eVal,eVec\n",
    "\n",
    "def fitKDE(obs,bWidth=.25,kernel='gaussian',x=None):\n",
    "    # Fit kernel to a series of obs, and derive the prob of obs\n",
    "    # x is the array of values on which the fit KDE will be evaluated\n",
    "    if len(obs.shape)==1:\n",
    "        obs=obs.reshape(-1,1)\n",
    "    kde=KernelDensity(kernel=kernel,bandwidth=bWidth).fit(obs)\n",
    "    if x is None:\n",
    "        x=np.unique(obs).reshape(-1,)\n",
    "    if len(x.shape)==1:\n",
    "        x=x.reshape(-1,1)\n",
    "    logProb=kde.score_samples(x) # log(density)\n",
    "    pdf=pd.Series(np.exp(logProb),index=x.flatten())\n",
    "    return pdf\n",
    "\n",
    "def cov2corr(cov):\n",
    "    # Derive the correlation matrix from a covariance matrix\n",
    "    std=np.sqrt(np.diag(cov))\n",
    "    corr=cov/np.outer(std,std)\n",
    "    corr[corr<-1],corr[corr>1]=-1,1 # numerical error\n",
    "    return corr\n",
    "\n",
    "def errPDFs(var,eVal,q,bWidth,pts=1000):\n",
    "    # Fit error\n",
    "    pdf0=mpPDF(var,q,pts) # theoretical pdf\n",
    "    pdf1=fitKDE(eVal,bWidth,x=pdf0.index.values) # empirical pdf\n",
    "    sse=np.sum((pdf1-pdf0)**2)\n",
    "    return sse\n",
    "\n",
    "def findMaxEval(eVal,q,bWidth):\n",
    "    # Find max random eVal by fitting Marcenko’s dist\n",
    "    out=minimize(lambda *x:errPDFs(*x),.5,args=(eVal,q,bWidth),\n",
    "    bounds=((1E-5,1-1E-5),))\n",
    "    if out['success']:\n",
    "        var=out['x'][0]\n",
    "    else:\n",
    "        var=1\n",
    "    eMax=var*(1+(1./q)**.5)**2\n",
    "    return eMax,var\n",
    "\n",
    "def denoisedCorr(eVal,eVec,nFacts):\n",
    "    # Remove noise from corr by fixing random eigenvalues\n",
    "    eVal_=np.diag(eVal).copy()\n",
    "    eVal_[nFacts:]=eVal_[nFacts:].sum()/float(eVal_.shape[0] - nFacts)\n",
    "    eVal_=np.diag(eVal_)\n",
    "    corr1=np.dot(eVec,eVal_).dot(eVec.T)\n",
    "    corr1=cov2corr(corr1)\n",
    "    return corr1\n",
    "\n",
    "def denoisedCorr2(eVal,eVec,nFacts,alpha=0):\n",
    "    # Remove noise from corr through targeted shrinkage\n",
    "    eValL,eVecL=eVal[:nFacts,:nFacts],eVec[:,:nFacts]\n",
    "    eValR,eVecR=eVal[nFacts:,nFacts:],eVec[:,nFacts:]\n",
    "    corr0=np.dot(eVecL,eValL).dot(eVecL.T)\n",
    "    corr1=np.dot(eVecR,eValR).dot(eVecR.T)\n",
    "    corr2=corr0+alpha*corr1+(1-alpha)*np.diag(np.diag(corr1))\n",
    "    return corr2\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#@njit\n",
    "def fillna_npwhere_njit(array, values):\n",
    "    if np.isnan(array.sum()):\n",
    "        array = np.where(np.isnan(array), values, array)\n",
    "    return array\n",
    "\n",
    "class RMTDenoising(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, bWidth=.01, alpha=.5, feature_0=True, sample=0.3, seed=2021):\n",
    "        self.bWidth = bWidth\n",
    "        self.alpha = alpha\n",
    "        self.feature_0 = feature_0\n",
    "        self.sample = sample\n",
    "        self.seed = seed\n",
    "    \n",
    "    def denoise(self, X):\n",
    "        sample = X.sample(frac=self.sample, random_state=self.seed)\n",
    "        q = X.shape[0] / X.shape[1]\n",
    "        cov = sample.cov().values\n",
    "        corr0 = cov2corr(cov)\n",
    "\n",
    "        eVal0, eVec0 = getPCA(corr0)\n",
    "        eMax0, var0 = findMaxEval(np.diag(eVal0), q, bWidth=self.bWidth)\n",
    "        nFacts0 = eVal0.shape[0] - np.diag(eVal0)[::-1].searchsorted(eMax0)\n",
    "        corr1 = denoisedCorr2(eVal0,eVec0,nFacts0,alpha=self.alpha)\n",
    "        eVal1, eVec1 = getPCA(corr1)\n",
    "        #result = np.hstack((np.diag(eVal1), var0))\n",
    "        #name = [f'eigen_{i+1}' for i in range(len(eVal1))] + ['var_explained']\n",
    "        return eVec1[:, :nFacts0]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self.feature_0:\n",
    "            self.cols_ = [c for c in X.columns if c != 'feature_0']\n",
    "        else:\n",
    "            self.cols_ = list(X.columns)\n",
    "        X_ = X[self.cols_]\n",
    "        self.W_ = self.denoise(X_)\n",
    "        self.dim_W_ = self.W_.shape[1]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        names = [f'proj_{i}' for i in range(self.dim_W_)]\n",
    "        projection = pd.DataFrame(fillna_npwhere_njit(X_[self.cols_].values, 0).dot(self.W_), columns=names)\n",
    "        if self.feature_0:\n",
    "            projection['feature_0'] = X['feature_0']\n",
    "        return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tf = RMTDenoising(sample=0.8)\n",
    "target_tf.fit(DATA[['resp', 'resp_1','resp_2','resp_3','resp_4'] + ['feature_0']])\n",
    "DATA['dresp'] = -target_tf.transform(DATA[['resp', 'resp_1','resp_2','resp_3','resp_4'] + ['feature_0']]).proj_0\n",
    "DATA[\"action\"]  =  (DATA['dresp'] > 0).astype('int') \n",
    "DATA['action_0'] = (DATA['resp'] > 0 ).astype('int') \n",
    "DATA['action_1'] = (DATA['resp_1'] > 0).astype('int')\n",
    "DATA['action_2'] = (DATA['resp_2'] > 0).astype('int')\n",
    "DATA['action_3'] = (DATA['resp_3'] > 0).astype('int')\n",
    "DATA['action_4'] = (DATA['resp_4'] > 0).astype('int')\n",
    "lab_cols = [\"action\", \"action_0\", \"action_1\", \"action_2\", \"action_3\", \"action_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components='mle', whiten=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "PcA = PCA(n_components='mle', whiten=True)\n",
    "PcA.fit(DATA[fea_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_K_Fold_Data(i, K, feature: np.ndarray, label: np.ndarray):\n",
    "    assert K > 1, \"K must be larger than 1.\"\n",
    "    Fold_size = feature.shape[0] // K\n",
    "    \n",
    "    train_feature, train_label = None, None\n",
    "    for j in range(K):\n",
    "        idx = slice(j * Fold_size, (j+1) * Fold_size)\n",
    "        part_feature, part_label = feature[idx], label[idx]\n",
    "        if j == i:\n",
    "            valid_feature, valid_label = part_feature, part_label\n",
    "        elif train_feature is None:\n",
    "            train_feature, train_label = part_feature, part_label\n",
    "        else:\n",
    "            train_feature = np.concatenate((train_feature, part_feature), axis=0)\n",
    "            train_label = np.concatenate((train_label, part_label), axis=0)\n",
    "            \n",
    "    return train_feature, train_label, valid_feature, valid_label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self, feature: np.ndarray, label: np.ndarray):\n",
    "        self.feature = feature\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.feature.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'feature': torch.tensor(self.feature[idx], dtype=torch.float),\n",
    "            'label': torch.tensor(self.label[idx], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(features, labels, BATCH_SIZE, shuffle=True):\n",
    "    data_set = dataset(features, labels)\n",
    "    return DataLoader(data_set, BATCH_SIZE, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, noise, on=True):\n",
    "        super().__init__()\n",
    "        self.noise = noise\n",
    "        self.on = True\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        if self.on:\n",
    "            return inputs + torch.autograd.Variable(torch.randn(inputs.size())* self.noise).to(\"cuda:0\")\n",
    "        else:\n",
    "            return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_size=[64, 16], noise=0.05, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.noise = noise\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.Gaussiannoise =  GaussianNoise(noise, on=True)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_shape),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(input_shape, hidden_size[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size[0]),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "            nn.ReLU(),)\n",
    "        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.Gaussiannoise(x)\n",
    "        encoding = self.encoder(x)\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_shape, hidden_size=[64, 16], dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.BatchNorm1d(hidden_size[1]),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size[1], hidden_size[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size[0]),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size[0], output_shape)\n",
    "        )\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        decoding = self.decoder(x)\n",
    "        return decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Decoder(nn.Module):\n",
    "     def __init__(self, input_shape, output_shape, hidden_size=[64, 16], dropout_rate=0):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_shape, hidden_size, )\n",
    "        self.decoder = Decoder(output_shape, hidden_size, )\n",
    "    \n",
    "     def forward(self, x):\n",
    "        encoding = self.encoder(x)\n",
    "        decoding = self.decoder(encoding)\n",
    "        return decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, train_dataloader, loss_fn, device):\n",
    "    model.train()\n",
    "    Final_loss = 0\n",
    "    for train_data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        features = train_data[\"feature\"].to(device)\n",
    "        label = train_data[\"feature\"].to(device)\n",
    "        \n",
    "        output = model(features)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        Final_loss += loss.item()\n",
    "    Final_loss /= len(train_dataloader)\n",
    "    return Final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_fn(model, valid_dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for valid_data in valid_dataloader:\n",
    "        features = valid_data[\"feature\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(features)\n",
    "        preds.append(output.detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds).reshape(-1, 130)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0 EPOCH:  0 train_loss=3.50765\n",
      "FOLD 0 EPOCH:  1 train_loss=2.70289\n",
      "FOLD 0 EPOCH:  2 train_loss=2.54063\n",
      "FOLD 0 EPOCH:  3 train_loss=2.46370\n",
      "FOLD 0 EPOCH:  4 train_loss=2.41318\n",
      "FOLD 0 EPOCH:  5 train_loss=2.39544\n",
      "FOLD 0 EPOCH:  6 train_loss=2.36164\n",
      "FOLD 0 EPOCH:  7 train_loss=2.34239\n",
      "FOLD 0 EPOCH:  8 train_loss=2.31756\n",
      "FOLD 0 EPOCH:  9 train_loss=2.29953\n",
      "FOLD 0 EPOCH: 10 train_loss=2.28404\n",
      "FOLD 0 EPOCH: 11 train_loss=2.27806\n",
      "FOLD 0 EPOCH: 12 train_loss=2.27266\n",
      "FOLD 0 EPOCH: 13 train_loss=2.25307\n",
      "FOLD 0 EPOCH: 14 train_loss=2.25179\n",
      "FOLD 0 EPOCH: 15 train_loss=2.24575\n",
      "FOLD 0 EPOCH: 16 train_loss=2.24151\n",
      "FOLD 0 EPOCH: 17 train_loss=2.23947\n",
      "FOLD 0 EPOCH: 18 train_loss=2.23573\n",
      "FOLD 0 EPOCH: 19 train_loss=2.23563\n",
      "FOLD 0 EPOCH: 20 train_loss=2.23033\n",
      "FOLD 0 EPOCH: 21 train_loss=2.22364\n",
      "FOLD 0 EPOCH: 22 train_loss=2.21957\n",
      "FOLD 0 EPOCH: 23 train_loss=2.22002\n",
      "FOLD 0 EPOCH: 24 train_loss=2.21650\n",
      "FOLD 0 EPOCH: 25 train_loss=2.20013\n",
      "FOLD 0 EPOCH: 26 train_loss=2.19691\n",
      "FOLD 0 EPOCH: 27 train_loss=2.21559\n",
      "FOLD 0 EPOCH: 28 train_loss=2.20208\n",
      "FOLD 0 EPOCH: 29 train_loss=2.19183\n",
      "FOLD 0 EPOCH: 30 train_loss=2.20040\n",
      "FOLD 0 EPOCH: 31 train_loss=2.20430\n",
      "FOLD 0 EPOCH: 32 train_loss=2.19535\n",
      "FOLD 0 EPOCH: 33 train_loss=2.19483\n",
      "FOLD 0 EPOCH: 34 train_loss=2.19093\n",
      "FOLD 0 EPOCH: 35 train_loss=2.19042\n",
      "FOLD 0 EPOCH: 36 train_loss=2.19022\n",
      "FOLD 0 EPOCH: 37 train_loss=2.18430\n",
      "FOLD 0 EPOCH: 38 train_loss=2.18951\n",
      "FOLD 0 EPOCH: 39 train_loss=2.18855\n",
      "FOLD 0 EPOCH: 40 train_loss=2.18642\n",
      "FOLD 0 EPOCH: 41 train_loss=2.18718\n",
      "FOLD 0 EPOCH: 42 train_loss=2.19111\n",
      "FOLD 0 EPOCH: 43 train_loss=2.18336\n",
      "FOLD 0 EPOCH: 44 train_loss=2.18341\n",
      "FOLD 0 EPOCH: 45 train_loss=2.18702\n",
      "FOLD 0 EPOCH: 46 train_loss=2.18424\n",
      "FOLD 0 EPOCH: 47 train_loss=2.18362\n",
      "FOLD 0 EPOCH: 48 train_loss=2.19576\n",
      "FOLD 0 EPOCH: 49 train_loss=2.17722\n"
     ]
    }
   ],
   "source": [
    "TRAIN_MODE = True\n",
    "EPOCHS = 50\n",
    "DEVICE = \"cuda:0\"\n",
    "BATCH_SIZE = 10240\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "K = 1\n",
    "\n",
    "if TRAIN_MODE:\n",
    "    for i in range(K):\n",
    "        #train_feature, train_label, valid_feature, valid_label =  Get_K_Fold_Data(K, i, DATA[fea_cols].values, DATA[lab_cols].values)\n",
    "        #print(train_feature, train_label, valid_feature, valid_label)\n",
    "        train_dataloader = dataloader(DATA[fea_cols].values, DATA[lab_cols].values, BATCH_SIZE=BATCH_SIZE, shuffle=True)\n",
    "        #valid_dataloader = dataloader(valid_feature, valid_label, BATCH_SIZE=BATCH_SIZE, shuffle=False)\n",
    "        torch.cuda.empty_cache()\n",
    "        encoder_decoder = Encoder_Decoder(len(fea_cols), len(fea_cols)).to(DEVICE)\n",
    "        opt = torch.optim.Adam(encoder_decoder.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        for epo in range(EPOCHS):\n",
    "            train_loss = train_fn(encoder_decoder, opt, train_dataloader, loss_fn, DEVICE)\n",
    "            #valid_pred = inference_fn(encoder_decoder, valid_dataloader, DEVICE)\n",
    "            #valid_loss = float((loss_fn(torch.FloatTensor(valid_pred), torch.FloatTensor(valid_feature))).detach().cpu().numpy())\n",
    "            #print(f\"FOLD{i:2} EPOCH:{epo:3} train_loss={train_loss:.5f} valid_loss={valid_loss:.5f}\")\n",
    "            print(f\"FOLD{i:2} EPOCH:{epo:3} train_loss={train_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder_Decoder(\n",
       "  (encoder): Encoder(\n",
       "    (Gaussiannoise): GaussianNoise()\n",
       "    (encoder): Sequential(\n",
       "      (0): BatchNorm1d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=132, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (7): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoder): Sequential(\n",
       "      (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=64, out_features=132, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder.eval()\n",
    "encoder_decoder.to(\"cpu\")\n",
    "Encoder_Decoder_Save_Path = \"../model_02_18/encoder_decoder_02_18.pth\"\n",
    "torch.save(encoder_decoder.state_dict(), Encoder_Decoder_Save_Path)\n",
    "\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    " \n",
    "#encoder_decoder = Encoder_Decoder(len(fea_cols), len(fea_cols)).to(DEVICE)\n",
    "\n",
    "#encoder_decoder.load_state_dict(torch.load(Encoder_Decoder_Save_Path)) \n",
    "encoder_decoder.to(DEVICE)\n",
    "encoder_decoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_size=[64, 32], noise=0.05, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_shape),\n",
    "            #GaussianNoise(noise),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(input_shape, hidden_size[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size[0]),\n",
    "            #GaussianNoise(noise),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, hidden_size, input_shape, output_shape):\n",
    "        super().__init__()\n",
    "        self.encoder_decoder = Encoder_Decoder(input_shape[0], input_shape[0])\n",
    "        self.block_1 = ResnetBlock(input_shape[1])\n",
    "        self.block_2 = ResnetBlock(hidden_size[0])\n",
    "        self.block_3 = ResnetBlock(hidden_size[1])\n",
    "        self.dense =  nn.Linear(hidden_size[2], output_shape)\n",
    "        \n",
    "    def forward(self, raw_x, x):\n",
    "        encoding = self.encoder_decoder.encoder(raw_x)\n",
    "        x_1 = self.block_1(x)\n",
    "        x_2 = torch.cat([x_1, encoding], axis=1)\n",
    "        x_3 = self.block_2(x_2)\n",
    "        x_4 = torch.cat([x_3, encoding], axis=1)\n",
    "        x_5 = self.block_3(x_4)\n",
    "        x_6 = self.dense(x_5)\n",
    "        return x_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn_(model, optimizer, train_dataloader, loss_fn, device, pca):\n",
    "    model.train()\n",
    "    Final_loss = 0\n",
    "    for train_data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        raw_features = train_data[\"feature\"]\n",
    "        label = train_data[\"label\"].to(device)\n",
    "        features = torch.FloatTensor(pca.transform(raw_features.numpy())).to(device)\n",
    "        #print(features)\n",
    "        raw_features = train_data[\"feature\"].to(device)\n",
    "        #print(raw_features)\n",
    "        output = model(raw_features, features)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        Final_loss += loss.item()\n",
    "    Final_loss /= len(train_dataloader)\n",
    "    return Final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_fn_(model, valid_dataloader, device, pca):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for valid_data in valid_dataloader:\n",
    "        raw_features = valid_data[\"feature\"]\n",
    "        label = valid_data[\"label\"].to(device)\n",
    "        features = torch.FloatTensor(pca.transform(raw_features.numpy())).to(device)\n",
    "        raw_features = valid_data[\"feature\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(raw_features, features)\n",
    "        preds.append(output.detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds).reshape(-1, 6)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_K_Fold_Data_(i, K, df: pd.DataFrame, fea_cols, lab_cols):\n",
    "    assert K > 1, \"K must be larger than 1.\"\n",
    "    Fold_size = len(df) // K\n",
    "    feature = df[fea_cols].values\n",
    "    label = df[lab_cols].values\n",
    "    train_feature, train_label = None, None\n",
    "    for j in range(K):\n",
    "        idx = slice(j * Fold_size, (j+1) * Fold_size)\n",
    "        part_feature, part_label = feature[idx], label[idx]\n",
    "        if j == i:\n",
    "            valid_feature, valid_label = part_feature, part_label\n",
    "            df_valid = df[idx]\n",
    "        elif train_feature is None:\n",
    "            train_feature, train_label = part_feature, part_label\n",
    "        else:\n",
    "            train_feature = np.concatenate((train_feature, part_feature), axis=0)\n",
    "            train_label = np.concatenate((train_label, part_label), axis=0)\n",
    "            \n",
    "    return train_feature, train_label, valid_feature, valid_label, df_valid        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_score_bincount(date, weight, resp, action):\n",
    "    count_i = len(np.unique(date))\n",
    "    Pi = np.bincount(date, weight * resp * action)\n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n",
    "    u = np.clip(t, 0, 6) * np.sum(Pi)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0 EPOCH:  0 train_loss=0.69533 valid_loss=0.69235 valid_auc=0.51685 cum_return=9.14193 valid_uility_score=2.65453\n",
      "FOLD 0 EPOCH:  1 train_loss=0.69291 valid_loss=0.69188 valid_auc=0.52449 cum_return=43.84440 valid_uility_score=79.71580\n",
      "FOLD 0 EPOCH:  2 train_loss=0.69241 valid_loss=0.69118 valid_auc=0.53314 cum_return=80.22290 valid_uility_score=247.40573\n",
      "FOLD 0 EPOCH:  3 train_loss=0.69187 valid_loss=0.69082 valid_auc=0.53709 cum_return=93.64360 valid_uility_score=366.30887\n",
      "FOLD 0 EPOCH:  4 train_loss=0.69165 valid_loss=0.69068 valid_auc=0.53774 cum_return=98.91283 valid_uility_score=429.73428\n",
      "FOLD 0 EPOCH:  5 train_loss=0.69146 valid_loss=0.69054 valid_auc=0.53832 cum_return=104.88398 valid_uility_score=459.11625\n",
      "FOLD 0 EPOCH:  6 train_loss=0.69138 valid_loss=0.69049 valid_auc=0.53926 cum_return=98.36925 valid_uility_score=421.15095\n",
      "FOLD 0 EPOCH:  7 train_loss=0.69129 valid_loss=0.69042 valid_auc=0.53975 cum_return=113.42351 valid_uility_score=472.53449\n",
      "FOLD 0 EPOCH:  8 train_loss=0.69122 valid_loss=0.69022 valid_auc=0.54100 cum_return=105.33052 valid_uility_score=427.71845\n",
      "FOLD 0 EPOCH:  9 train_loss=0.69113 valid_loss=0.69017 valid_auc=0.54072 cum_return=112.37114 valid_uility_score=542.39743\n",
      "FOLD 0 EPOCH: 10 train_loss=0.69109 valid_loss=0.68997 valid_auc=0.54170 cum_return=124.32478 valid_uility_score=584.23589\n",
      "FOLD 0 EPOCH: 11 train_loss=0.69104 valid_loss=0.69013 valid_auc=0.54159 cum_return=107.04544 valid_uility_score=400.67529\n",
      "FOLD 0 EPOCH: 12 train_loss=0.69103 valid_loss=0.69007 valid_auc=0.54155 cum_return=135.61180 valid_uility_score=667.89508\n",
      "FOLD 0 EPOCH: 13 train_loss=0.69100 valid_loss=0.69005 valid_auc=0.54199 cum_return=122.11992 valid_uility_score=594.01065\n",
      "FOLD 0 EPOCH: 14 train_loss=0.69097 valid_loss=0.68996 valid_auc=0.54214 cum_return=116.04984 valid_uility_score=494.90142\n",
      "FOLD 0 EPOCH: 15 train_loss=0.69101 valid_loss=0.69011 valid_auc=0.54269 cum_return=112.24038 valid_uility_score=526.91310\n",
      "FOLD 0 EPOCH: 16 train_loss=0.69100 valid_loss=0.69024 valid_auc=0.54200 cum_return=121.49987 valid_uility_score=579.64795\n",
      "FOLD 0 EPOCH: 17 train_loss=0.69096 valid_loss=0.68997 valid_auc=0.54173 cum_return=124.29071 valid_uility_score=585.34407\n",
      "FOLD 0 EPOCH: 18 train_loss=0.69091 valid_loss=0.69018 valid_auc=0.54187 cum_return=96.22352 valid_uility_score=361.82937\n",
      "FOLD 0 EPOCH: 19 train_loss=0.69087 valid_loss=0.68997 valid_auc=0.54261 cum_return=120.62445 valid_uility_score=568.89568\n",
      "FOLD 0 EPOCH: 20 train_loss=0.69095 valid_loss=0.68995 valid_auc=0.54295 cum_return=112.96753 valid_uility_score=565.75509\n",
      "FOLD 0 EPOCH: 21 train_loss=0.69094 valid_loss=0.68998 valid_auc=0.54226 cum_return=144.13862 valid_uility_score=795.30482\n",
      "FOLD 0 EPOCH: 22 train_loss=0.69088 valid_loss=0.69000 valid_auc=0.54338 cum_return=124.82692 valid_uility_score=619.26247\n",
      "FOLD 0 EPOCH: 23 train_loss=0.69095 valid_loss=0.69006 valid_auc=0.54267 cum_return=123.14570 valid_uility_score=612.83632\n",
      "FOLD 0 EPOCH: 24 train_loss=0.69088 valid_loss=0.68997 valid_auc=0.54250 cum_return=115.13937 valid_uility_score=562.43474\n",
      "FOLD 0 EPOCH: 25 train_loss=0.69090 valid_loss=0.68993 valid_auc=0.54176 cum_return=125.35444 valid_uility_score=582.32322\n",
      "FOLD 0 EPOCH: 26 train_loss=0.69091 valid_loss=0.68986 valid_auc=0.54207 cum_return=126.40771 valid_uility_score=610.60262\n",
      "FOLD 0 EPOCH: 27 train_loss=0.69091 valid_loss=0.69020 valid_auc=0.54269 cum_return=121.02837 valid_uility_score=587.28291\n",
      "FOLD 0 EPOCH: 28 train_loss=0.69091 valid_loss=0.68996 valid_auc=0.54196 cum_return=125.14812 valid_uility_score=546.28345\n",
      "FOLD 0 EPOCH: 29 train_loss=0.69088 valid_loss=0.69004 valid_auc=0.54277 cum_return=121.81624 valid_uility_score=592.28411\n",
      "FOLD 1 EPOCH:  0 train_loss=0.69492 valid_loss=0.69231 valid_auc=0.52289 cum_return=6.36600 valid_uility_score=1.06946\n",
      "FOLD 1 EPOCH:  1 train_loss=0.69288 valid_loss=0.69200 valid_auc=0.52791 cum_return=145.27535 valid_uility_score=756.00947\n",
      "FOLD 1 EPOCH:  2 train_loss=0.69258 valid_loss=0.69166 valid_auc=0.53164 cum_return=175.43737 valid_uility_score=814.88597\n",
      "FOLD 1 EPOCH:  3 train_loss=0.69205 valid_loss=0.69089 valid_auc=0.53856 cum_return=248.86778 valid_uility_score=1493.20666\n",
      "FOLD 1 EPOCH:  4 train_loss=0.69165 valid_loss=0.69061 valid_auc=0.54068 cum_return=261.78514 valid_uility_score=1570.71085\n",
      "FOLD 1 EPOCH:  5 train_loss=0.69150 valid_loss=0.69052 valid_auc=0.54163 cum_return=272.14175 valid_uility_score=1632.85048\n",
      "FOLD 1 EPOCH:  6 train_loss=0.69135 valid_loss=0.69036 valid_auc=0.54226 cum_return=285.67887 valid_uility_score=1714.07322\n",
      "FOLD 1 EPOCH:  7 train_loss=0.69129 valid_loss=0.69023 valid_auc=0.54227 cum_return=263.94481 valid_uility_score=1583.66885\n",
      "FOLD 1 EPOCH:  8 train_loss=0.69123 valid_loss=0.68997 valid_auc=0.54380 cum_return=263.65466 valid_uility_score=1581.92797\n",
      "FOLD 1 EPOCH:  9 train_loss=0.69112 valid_loss=0.69002 valid_auc=0.54370 cum_return=267.49687 valid_uility_score=1604.98123\n",
      "FOLD 1 EPOCH: 10 train_loss=0.69104 valid_loss=0.69009 valid_auc=0.54361 cum_return=257.84396 valid_uility_score=1547.06378\n",
      "FOLD 1 EPOCH: 11 train_loss=0.69103 valid_loss=0.68992 valid_auc=0.54525 cum_return=276.21570 valid_uility_score=1657.29418\n",
      "FOLD 1 EPOCH: 12 train_loss=0.69101 valid_loss=0.69010 valid_auc=0.54441 cum_return=243.29342 valid_uility_score=1459.76051\n",
      "FOLD 1 EPOCH: 13 train_loss=0.69097 valid_loss=0.68991 valid_auc=0.54422 cum_return=249.23305 valid_uility_score=1495.39830\n",
      "FOLD 1 EPOCH: 14 train_loss=0.69097 valid_loss=0.68994 valid_auc=0.54433 cum_return=243.37579 valid_uility_score=1460.25474\n",
      "FOLD 1 EPOCH: 15 train_loss=0.69100 valid_loss=0.69005 valid_auc=0.54352 cum_return=233.60838 valid_uility_score=1401.65030\n",
      "FOLD 1 EPOCH: 16 train_loss=0.69098 valid_loss=0.69005 valid_auc=0.54369 cum_return=245.20185 valid_uility_score=1471.21107\n",
      "FOLD 1 EPOCH: 17 train_loss=0.69092 valid_loss=0.69005 valid_auc=0.54382 cum_return=235.73406 valid_uility_score=1365.39167\n",
      "FOLD 1 EPOCH: 18 train_loss=0.69096 valid_loss=0.68982 valid_auc=0.54466 cum_return=263.96892 valid_uility_score=1583.81349\n",
      "FOLD 1 EPOCH: 19 train_loss=0.69095 valid_loss=0.68999 valid_auc=0.54369 cum_return=223.91937 valid_uility_score=1343.51620\n",
      "FOLD 1 EPOCH: 20 train_loss=0.69092 valid_loss=0.68990 valid_auc=0.54409 cum_return=231.58698 valid_uility_score=1366.74408\n",
      "FOLD 1 EPOCH: 21 train_loss=0.69090 valid_loss=0.68989 valid_auc=0.54445 cum_return=220.50908 valid_uility_score=1323.05450\n",
      "FOLD 1 EPOCH: 22 train_loss=0.69089 valid_loss=0.69010 valid_auc=0.54459 cum_return=223.96294 valid_uility_score=1188.31086\n",
      "FOLD 1 EPOCH: 23 train_loss=0.69094 valid_loss=0.69009 valid_auc=0.54501 cum_return=234.97961 valid_uility_score=1409.87768\n",
      "FOLD 1 EPOCH: 24 train_loss=0.69094 valid_loss=0.69000 valid_auc=0.54421 cum_return=226.53007 valid_uility_score=1359.18039\n",
      "FOLD 1 EPOCH: 25 train_loss=0.69089 valid_loss=0.68982 valid_auc=0.54456 cum_return=231.88593 valid_uility_score=1391.31560\n",
      "FOLD 1 EPOCH: 26 train_loss=0.69092 valid_loss=0.69006 valid_auc=0.54314 cum_return=212.97882 valid_uility_score=1277.87292\n",
      "FOLD 1 EPOCH: 27 train_loss=0.69089 valid_loss=0.68990 valid_auc=0.54473 cum_return=229.78414 valid_uility_score=1378.70484\n",
      "FOLD 1 EPOCH: 28 train_loss=0.69082 valid_loss=0.68989 valid_auc=0.54511 cum_return=261.21131 valid_uility_score=1567.26787\n",
      "FOLD 1 EPOCH: 29 train_loss=0.69096 valid_loss=0.68987 valid_auc=0.54464 cum_return=227.38699 valid_uility_score=1364.32196\n",
      "FOLD 2 EPOCH:  0 train_loss=0.69493 valid_loss=0.69257 valid_auc=0.51629 cum_return=-25.15025 valid_uility_score=-0.00000\n",
      "FOLD 2 EPOCH:  1 train_loss=0.69285 valid_loss=0.69233 valid_auc=0.52034 cum_return=9.44678 valid_uility_score=1.67027\n",
      "FOLD 2 EPOCH:  2 train_loss=0.69252 valid_loss=0.69203 valid_auc=0.52313 cum_return=2.55137 valid_uility_score=0.14054\n",
      "FOLD 2 EPOCH:  3 train_loss=0.69215 valid_loss=0.69121 valid_auc=0.53261 cum_return=95.54681 valid_uility_score=235.54999\n",
      "FOLD 2 EPOCH:  4 train_loss=0.69167 valid_loss=0.69103 valid_auc=0.53401 cum_return=132.22808 valid_uility_score=447.62251\n",
      "FOLD 2 EPOCH:  5 train_loss=0.69144 valid_loss=0.69089 valid_auc=0.53546 cum_return=125.50838 valid_uility_score=376.90089\n",
      "FOLD 2 EPOCH:  6 train_loss=0.69133 valid_loss=0.69089 valid_auc=0.53472 cum_return=91.81653 valid_uility_score=186.19247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2 EPOCH:  7 train_loss=0.69123 valid_loss=0.69084 valid_auc=0.53569 cum_return=116.01646 valid_uility_score=381.04689\n",
      "FOLD 2 EPOCH:  8 train_loss=0.69118 valid_loss=0.69061 valid_auc=0.53657 cum_return=113.60272 valid_uility_score=327.69475\n",
      "FOLD 2 EPOCH:  9 train_loss=0.69103 valid_loss=0.69061 valid_auc=0.53701 cum_return=128.12081 valid_uility_score=448.03970\n",
      "FOLD 2 EPOCH: 10 train_loss=0.69100 valid_loss=0.69050 valid_auc=0.53762 cum_return=114.47786 valid_uility_score=315.88708\n",
      "FOLD 2 EPOCH: 11 train_loss=0.69098 valid_loss=0.69055 valid_auc=0.53771 cum_return=101.82529 valid_uility_score=255.04370\n",
      "FOLD 2 EPOCH: 12 train_loss=0.69096 valid_loss=0.69050 valid_auc=0.53838 cum_return=128.13740 valid_uility_score=444.79266\n",
      "FOLD 2 EPOCH: 13 train_loss=0.69096 valid_loss=0.69048 valid_auc=0.53820 cum_return=146.37285 valid_uility_score=503.71633\n",
      "FOLD 2 EPOCH: 14 train_loss=0.69098 valid_loss=0.69058 valid_auc=0.53823 cum_return=143.52169 valid_uility_score=501.42229\n",
      "FOLD 2 EPOCH: 15 train_loss=0.69085 valid_loss=0.69049 valid_auc=0.53778 cum_return=110.15823 valid_uility_score=332.80617\n",
      "FOLD 2 EPOCH: 16 train_loss=0.69087 valid_loss=0.69047 valid_auc=0.53832 cum_return=159.99951 valid_uility_score=631.50524\n",
      "FOLD 2 EPOCH: 17 train_loss=0.69086 valid_loss=0.69056 valid_auc=0.53811 cum_return=119.29393 valid_uility_score=330.22472\n",
      "FOLD 2 EPOCH: 18 train_loss=0.69084 valid_loss=0.69041 valid_auc=0.53886 cum_return=129.54720 valid_uility_score=411.61028\n",
      "FOLD 2 EPOCH: 19 train_loss=0.69090 valid_loss=0.69047 valid_auc=0.53904 cum_return=169.21256 valid_uility_score=677.14759\n",
      "FOLD 2 EPOCH: 20 train_loss=0.69088 valid_loss=0.69032 valid_auc=0.53960 cum_return=123.92436 valid_uility_score=339.98870\n",
      "FOLD 2 EPOCH: 21 train_loss=0.69081 valid_loss=0.69052 valid_auc=0.53920 cum_return=121.56838 valid_uility_score=309.48954\n",
      "FOLD 2 EPOCH: 22 train_loss=0.69081 valid_loss=0.69046 valid_auc=0.53859 cum_return=116.12980 valid_uility_score=377.71540\n",
      "FOLD 2 EPOCH: 23 train_loss=0.69090 valid_loss=0.69059 valid_auc=0.53810 cum_return=107.44119 valid_uility_score=240.76641\n",
      "FOLD 2 EPOCH: 24 train_loss=0.69076 valid_loss=0.69053 valid_auc=0.53860 cum_return=134.62537 valid_uility_score=508.51388\n",
      "FOLD 2 EPOCH: 25 train_loss=0.69091 valid_loss=0.69037 valid_auc=0.53890 cum_return=151.94502 valid_uility_score=602.40131\n",
      "FOLD 2 EPOCH: 26 train_loss=0.69084 valid_loss=0.69064 valid_auc=0.53807 cum_return=121.84581 valid_uility_score=388.67107\n",
      "FOLD 2 EPOCH: 27 train_loss=0.69083 valid_loss=0.69051 valid_auc=0.53713 cum_return=112.58736 valid_uility_score=280.54164\n",
      "FOLD 2 EPOCH: 28 train_loss=0.69077 valid_loss=0.69046 valid_auc=0.53856 cum_return=109.60134 valid_uility_score=304.61879\n",
      "FOLD 2 EPOCH: 29 train_loss=0.69081 valid_loss=0.69031 valid_auc=0.53913 cum_return=160.65248 valid_uility_score=663.18403\n",
      "FOLD 3 EPOCH:  0 train_loss=0.69476 valid_loss=0.69231 valid_auc=0.52355 cum_return=35.45786 valid_uility_score=34.22691\n",
      "FOLD 3 EPOCH:  1 train_loss=0.69287 valid_loss=0.69191 valid_auc=0.52767 cum_return=33.32132 valid_uility_score=38.98269\n",
      "FOLD 3 EPOCH:  2 train_loss=0.69256 valid_loss=0.69155 valid_auc=0.53156 cum_return=91.65709 valid_uility_score=256.60240\n",
      "FOLD 3 EPOCH:  3 train_loss=0.69214 valid_loss=0.69063 valid_auc=0.53945 cum_return=181.95567 valid_uility_score=671.70296\n",
      "FOLD 3 EPOCH:  4 train_loss=0.69166 valid_loss=0.69049 valid_auc=0.54022 cum_return=214.08395 valid_uility_score=855.97497\n",
      "FOLD 3 EPOCH:  5 train_loss=0.69150 valid_loss=0.69041 valid_auc=0.54247 cum_return=244.74229 valid_uility_score=1045.46880\n",
      "FOLD 3 EPOCH:  6 train_loss=0.69144 valid_loss=0.69025 valid_auc=0.54367 cum_return=259.97503 valid_uility_score=1150.22989\n",
      "FOLD 3 EPOCH:  7 train_loss=0.69139 valid_loss=0.69016 valid_auc=0.54432 cum_return=258.74778 valid_uility_score=1028.04596\n",
      "FOLD 3 EPOCH:  8 train_loss=0.69127 valid_loss=0.68997 valid_auc=0.54456 cum_return=294.38354 valid_uility_score=1267.25569\n",
      "FOLD 3 EPOCH:  9 train_loss=0.69117 valid_loss=0.68989 valid_auc=0.54536 cum_return=288.08382 valid_uility_score=1322.52782\n",
      "FOLD 3 EPOCH: 10 train_loss=0.69120 valid_loss=0.68991 valid_auc=0.54588 cum_return=284.07219 valid_uility_score=1481.72594\n",
      "FOLD 3 EPOCH: 11 train_loss=0.69106 valid_loss=0.68983 valid_auc=0.54695 cum_return=307.16262 valid_uility_score=1591.79709\n",
      "FOLD 3 EPOCH: 12 train_loss=0.69110 valid_loss=0.68989 valid_auc=0.54636 cum_return=259.28605 valid_uility_score=1269.73229\n",
      "FOLD 3 EPOCH: 13 train_loss=0.69105 valid_loss=0.68997 valid_auc=0.54698 cum_return=305.94945 valid_uility_score=1527.78218\n",
      "FOLD 3 EPOCH: 14 train_loss=0.69099 valid_loss=0.68963 valid_auc=0.54798 cum_return=327.62306 valid_uility_score=1816.12169\n",
      "FOLD 3 EPOCH: 15 train_loss=0.69104 valid_loss=0.68973 valid_auc=0.54703 cum_return=337.87312 valid_uility_score=2027.23870\n",
      "FOLD 3 EPOCH: 16 train_loss=0.69100 valid_loss=0.68980 valid_auc=0.54702 cum_return=295.16380 valid_uility_score=1770.98278\n",
      "FOLD 3 EPOCH: 17 train_loss=0.69098 valid_loss=0.68976 valid_auc=0.54669 cum_return=294.81118 valid_uility_score=1646.40461\n",
      "FOLD 3 EPOCH: 18 train_loss=0.69099 valid_loss=0.68956 valid_auc=0.54826 cum_return=311.74254 valid_uility_score=1653.98694\n",
      "FOLD 3 EPOCH: 19 train_loss=0.69093 valid_loss=0.68984 valid_auc=0.54672 cum_return=289.84494 valid_uility_score=1739.06966\n",
      "FOLD 3 EPOCH: 20 train_loss=0.69095 valid_loss=0.68971 valid_auc=0.54606 cum_return=282.95235 valid_uility_score=1617.11386\n",
      "FOLD 3 EPOCH: 21 train_loss=0.69093 valid_loss=0.68987 valid_auc=0.54754 cum_return=304.82952 valid_uility_score=1828.97712\n",
      "FOLD 3 EPOCH: 22 train_loss=0.69089 valid_loss=0.68977 valid_auc=0.54555 cum_return=249.80714 valid_uility_score=1432.00500\n",
      "FOLD 3 EPOCH: 23 train_loss=0.69093 valid_loss=0.68978 valid_auc=0.54534 cum_return=274.46061 valid_uility_score=1367.92384\n",
      "FOLD 3 EPOCH: 24 train_loss=0.69089 valid_loss=0.68970 valid_auc=0.54661 cum_return=321.03510 valid_uility_score=1702.81068\n",
      "FOLD 3 EPOCH: 25 train_loss=0.69096 valid_loss=0.68963 valid_auc=0.54756 cum_return=304.41395 valid_uility_score=1546.32318\n",
      "FOLD 3 EPOCH: 26 train_loss=0.69091 valid_loss=0.68966 valid_auc=0.54704 cum_return=288.98418 valid_uility_score=1596.37087\n",
      "FOLD 3 EPOCH: 27 train_loss=0.69090 valid_loss=0.68968 valid_auc=0.54698 cum_return=333.91247 valid_uility_score=1850.35772\n",
      "FOLD 3 EPOCH: 28 train_loss=0.69088 valid_loss=0.68960 valid_auc=0.54807 cum_return=308.11416 valid_uility_score=1687.31251\n",
      "FOLD 3 EPOCH: 29 train_loss=0.69089 valid_loss=0.68969 valid_auc=0.54811 cum_return=326.41671 valid_uility_score=1729.07518\n",
      "FOLD 4 EPOCH:  0 train_loss=0.69460 valid_loss=0.69259 valid_auc=0.51640 cum_return=-109.85657 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH:  1 train_loss=0.69284 valid_loss=0.69232 valid_auc=0.51995 cum_return=-36.64598 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH:  2 train_loss=0.69246 valid_loss=0.69187 valid_auc=0.52661 cum_return=-65.31439 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH:  3 train_loss=0.69195 valid_loss=0.69111 valid_auc=0.53293 cum_return=-17.01767 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH:  4 train_loss=0.69154 valid_loss=0.69107 valid_auc=0.53249 cum_return=-24.38331 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH:  5 train_loss=0.69140 valid_loss=0.69090 valid_auc=0.53370 cum_return=-22.94514 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH:  6 train_loss=0.69129 valid_loss=0.69092 valid_auc=0.53338 cum_return=-41.31905 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH:  7 train_loss=0.69124 valid_loss=0.69082 valid_auc=0.53405 cum_return=-16.00147 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH:  8 train_loss=0.69111 valid_loss=0.69066 valid_auc=0.53574 cum_return=-0.69487 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH:  9 train_loss=0.69105 valid_loss=0.69061 valid_auc=0.53567 cum_return=-19.67286 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 10 train_loss=0.69102 valid_loss=0.69056 valid_auc=0.53649 cum_return=-2.16804 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 11 train_loss=0.69100 valid_loss=0.69064 valid_auc=0.53567 cum_return=-31.38959 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 12 train_loss=0.69096 valid_loss=0.69068 valid_auc=0.53572 cum_return=-14.28551 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 13 train_loss=0.69094 valid_loss=0.69065 valid_auc=0.53594 cum_return=18.83420 valid_uility_score=8.27698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 4 EPOCH: 14 train_loss=0.69090 valid_loss=0.69069 valid_auc=0.53612 cum_return=12.90550 valid_uility_score=4.10051\n",
      "FOLD 4 EPOCH: 15 train_loss=0.69094 valid_loss=0.69072 valid_auc=0.53525 cum_return=-23.53029 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 16 train_loss=0.69088 valid_loss=0.69050 valid_auc=0.53682 cum_return=-8.31815 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 17 train_loss=0.69088 valid_loss=0.69050 valid_auc=0.53618 cum_return=-2.03816 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 18 train_loss=0.69083 valid_loss=0.69052 valid_auc=0.53673 cum_return=-13.60046 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 19 train_loss=0.69086 valid_loss=0.69050 valid_auc=0.53635 cum_return=20.06804 valid_uility_score=9.82645\n",
      "FOLD 4 EPOCH: 20 train_loss=0.69090 valid_loss=0.69064 valid_auc=0.53560 cum_return=-8.03175 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 21 train_loss=0.69080 valid_loss=0.69057 valid_auc=0.53712 cum_return=-4.11172 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 22 train_loss=0.69087 valid_loss=0.69067 valid_auc=0.53590 cum_return=-5.98179 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 23 train_loss=0.69086 valid_loss=0.69061 valid_auc=0.53564 cum_return=34.66302 valid_uility_score=35.51266\n",
      "FOLD 4 EPOCH: 24 train_loss=0.69085 valid_loss=0.69057 valid_auc=0.53594 cum_return=24.37081 valid_uility_score=13.87605\n",
      "FOLD 4 EPOCH: 25 train_loss=0.69079 valid_loss=0.69047 valid_auc=0.53703 cum_return=-28.20296 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 26 train_loss=0.69085 valid_loss=0.69059 valid_auc=0.53564 cum_return=6.19898 valid_uility_score=1.05836\n",
      "FOLD 4 EPOCH: 27 train_loss=0.69081 valid_loss=0.69070 valid_auc=0.53517 cum_return=-34.29891 valid_uility_score=-0.00000\n",
      "FOLD 4 EPOCH: 28 train_loss=0.69078 valid_loss=0.69052 valid_auc=0.53634 cum_return=56.47049 valid_uility_score=100.02986\n",
      "FOLD 4 EPOCH: 29 train_loss=0.69081 valid_loss=0.69061 valid_auc=0.53583 cum_return=15.56435 valid_uility_score=5.97385\n",
      "FOLD 5 EPOCH:  0 train_loss=0.69464 valid_loss=0.69225 valid_auc=0.52481 cum_return=93.09180 valid_uility_score=234.14044\n",
      "FOLD 5 EPOCH:  1 train_loss=0.69282 valid_loss=0.69175 valid_auc=0.53087 cum_return=125.38882 valid_uility_score=273.40249\n",
      "FOLD 5 EPOCH:  2 train_loss=0.69246 valid_loss=0.69130 valid_auc=0.53579 cum_return=154.55187 valid_uility_score=545.50989\n",
      "FOLD 5 EPOCH:  3 train_loss=0.69189 valid_loss=0.69065 valid_auc=0.53930 cum_return=195.66009 valid_uility_score=736.45244\n",
      "FOLD 5 EPOCH:  4 train_loss=0.69163 valid_loss=0.69052 valid_auc=0.53919 cum_return=195.32910 valid_uility_score=788.36608\n",
      "FOLD 5 EPOCH:  5 train_loss=0.69150 valid_loss=0.69054 valid_auc=0.53948 cum_return=193.20868 valid_uility_score=772.72938\n",
      "FOLD 5 EPOCH:  6 train_loss=0.69142 valid_loss=0.69052 valid_auc=0.54016 cum_return=205.43236 valid_uility_score=685.08119\n",
      "FOLD 5 EPOCH:  7 train_loss=0.69128 valid_loss=0.69043 valid_auc=0.53956 cum_return=192.10503 valid_uility_score=775.80242\n",
      "FOLD 5 EPOCH:  8 train_loss=0.69114 valid_loss=0.69023 valid_auc=0.54016 cum_return=219.40375 valid_uility_score=858.17327\n",
      "FOLD 5 EPOCH:  9 train_loss=0.69116 valid_loss=0.69021 valid_auc=0.54111 cum_return=194.08849 valid_uility_score=761.28094\n",
      "FOLD 5 EPOCH: 10 train_loss=0.69112 valid_loss=0.69023 valid_auc=0.54087 cum_return=181.69813 valid_uility_score=878.57399\n",
      "FOLD 5 EPOCH: 11 train_loss=0.69108 valid_loss=0.69005 valid_auc=0.54230 cum_return=219.05628 valid_uility_score=855.08335\n",
      "FOLD 5 EPOCH: 12 train_loss=0.69101 valid_loss=0.69010 valid_auc=0.54135 cum_return=199.93956 valid_uility_score=842.16161\n",
      "FOLD 5 EPOCH: 13 train_loss=0.69099 valid_loss=0.68982 valid_auc=0.54245 cum_return=221.26636 valid_uility_score=759.98266\n",
      "FOLD 5 EPOCH: 14 train_loss=0.69099 valid_loss=0.69001 valid_auc=0.54173 cum_return=196.34489 valid_uility_score=1008.26410\n",
      "FOLD 5 EPOCH: 15 train_loss=0.69095 valid_loss=0.68976 valid_auc=0.54406 cum_return=222.07123 valid_uility_score=793.81029\n",
      "FOLD 5 EPOCH: 16 train_loss=0.69095 valid_loss=0.68976 valid_auc=0.54309 cum_return=218.05755 valid_uility_score=840.09981\n",
      "FOLD 5 EPOCH: 17 train_loss=0.69099 valid_loss=0.68983 valid_auc=0.54404 cum_return=233.61228 valid_uility_score=938.52526\n",
      "FOLD 5 EPOCH: 18 train_loss=0.69094 valid_loss=0.69009 valid_auc=0.54400 cum_return=207.62720 valid_uility_score=1063.60173\n",
      "FOLD 5 EPOCH: 19 train_loss=0.69093 valid_loss=0.68979 valid_auc=0.54329 cum_return=211.23433 valid_uility_score=780.07526\n",
      "FOLD 5 EPOCH: 20 train_loss=0.69090 valid_loss=0.68979 valid_auc=0.54352 cum_return=194.95309 valid_uility_score=873.82984\n",
      "FOLD 5 EPOCH: 21 train_loss=0.69093 valid_loss=0.68998 valid_auc=0.54337 cum_return=223.74229 valid_uility_score=853.04230\n",
      "FOLD 5 EPOCH: 22 train_loss=0.69087 valid_loss=0.68974 valid_auc=0.54330 cum_return=219.52191 valid_uility_score=823.91760\n",
      "FOLD 5 EPOCH: 23 train_loss=0.69089 valid_loss=0.68993 valid_auc=0.54244 cum_return=181.82623 valid_uility_score=618.73981\n",
      "FOLD 5 EPOCH: 24 train_loss=0.69086 valid_loss=0.68959 valid_auc=0.54471 cum_return=247.54367 valid_uility_score=941.06082\n",
      "FOLD 5 EPOCH: 25 train_loss=0.69090 valid_loss=0.68983 valid_auc=0.54369 cum_return=220.71902 valid_uility_score=904.35056\n",
      "FOLD 5 EPOCH: 26 train_loss=0.69092 valid_loss=0.68999 valid_auc=0.54343 cum_return=202.45991 valid_uility_score=789.21571\n",
      "FOLD 5 EPOCH: 27 train_loss=0.69085 valid_loss=0.68991 valid_auc=0.54292 cum_return=211.77515 valid_uility_score=749.09118\n",
      "FOLD 5 EPOCH: 28 train_loss=0.69086 valid_loss=0.68965 valid_auc=0.54441 cum_return=213.56878 valid_uility_score=838.19502\n",
      "FOLD 5 EPOCH: 29 train_loss=0.69087 valid_loss=0.68979 valid_auc=0.54369 cum_return=212.56448 valid_uility_score=862.88985\n",
      "FOLD 6 EPOCH:  0 train_loss=0.69470 valid_loss=0.69246 valid_auc=0.51866 cum_return=51.57599 valid_uility_score=88.53311\n",
      "FOLD 6 EPOCH:  1 train_loss=0.69282 valid_loss=0.69218 valid_auc=0.52248 cum_return=42.73641 valid_uility_score=105.32950\n",
      "FOLD 6 EPOCH:  2 train_loss=0.69250 valid_loss=0.69191 valid_auc=0.52617 cum_return=78.91683 valid_uility_score=312.04307\n",
      "FOLD 6 EPOCH:  3 train_loss=0.69206 valid_loss=0.69118 valid_auc=0.53319 cum_return=118.74083 valid_uility_score=506.86940\n",
      "FOLD 6 EPOCH:  4 train_loss=0.69163 valid_loss=0.69101 valid_auc=0.53490 cum_return=116.14158 valid_uility_score=455.72863\n",
      "FOLD 6 EPOCH:  5 train_loss=0.69147 valid_loss=0.69094 valid_auc=0.53441 cum_return=114.90351 valid_uility_score=469.69896\n",
      "FOLD 6 EPOCH:  6 train_loss=0.69133 valid_loss=0.69089 valid_auc=0.53395 cum_return=107.79266 valid_uility_score=451.79230\n",
      "FOLD 6 EPOCH:  7 train_loss=0.69122 valid_loss=0.69077 valid_auc=0.53423 cum_return=114.00692 valid_uility_score=443.92559\n",
      "FOLD 6 EPOCH:  8 train_loss=0.69114 valid_loss=0.69052 valid_auc=0.53670 cum_return=160.24180 valid_uility_score=850.68378\n",
      "FOLD 6 EPOCH:  9 train_loss=0.69108 valid_loss=0.69063 valid_auc=0.53606 cum_return=148.31836 valid_uility_score=741.58173\n",
      "FOLD 6 EPOCH: 10 train_loss=0.69101 valid_loss=0.69049 valid_auc=0.53766 cum_return=163.80884 valid_uility_score=891.24370\n",
      "FOLD 6 EPOCH: 11 train_loss=0.69104 valid_loss=0.69050 valid_auc=0.53673 cum_return=152.77208 valid_uility_score=868.97856\n",
      "FOLD 6 EPOCH: 12 train_loss=0.69100 valid_loss=0.69066 valid_auc=0.53515 cum_return=146.87888 valid_uility_score=876.25404\n",
      "FOLD 6 EPOCH: 13 train_loss=0.69094 valid_loss=0.69043 valid_auc=0.53747 cum_return=167.13761 valid_uility_score=1002.82566\n",
      "FOLD 6 EPOCH: 14 train_loss=0.69093 valid_loss=0.69042 valid_auc=0.53823 cum_return=150.70850 valid_uility_score=870.03626\n",
      "FOLD 6 EPOCH: 15 train_loss=0.69095 valid_loss=0.69032 valid_auc=0.53866 cum_return=161.38231 valid_uility_score=855.67910\n",
      "FOLD 6 EPOCH: 16 train_loss=0.69093 valid_loss=0.69040 valid_auc=0.53745 cum_return=168.58467 valid_uility_score=1011.50801\n",
      "FOLD 6 EPOCH: 17 train_loss=0.69090 valid_loss=0.69053 valid_auc=0.53751 cum_return=168.39838 valid_uility_score=1010.39028\n",
      "FOLD 6 EPOCH: 18 train_loss=0.69087 valid_loss=0.69051 valid_auc=0.53624 cum_return=141.71663 valid_uility_score=805.98708\n",
      "FOLD 6 EPOCH: 19 train_loss=0.69085 valid_loss=0.69045 valid_auc=0.53731 cum_return=165.67067 valid_uility_score=923.64657\n",
      "FOLD 6 EPOCH: 20 train_loss=0.69089 valid_loss=0.69057 valid_auc=0.53713 cum_return=148.61941 valid_uility_score=891.71647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 6 EPOCH: 21 train_loss=0.69086 valid_loss=0.69046 valid_auc=0.53640 cum_return=150.65311 valid_uility_score=866.28569\n",
      "FOLD 6 EPOCH: 22 train_loss=0.69082 valid_loss=0.69042 valid_auc=0.53678 cum_return=158.28022 valid_uility_score=949.68130\n",
      "FOLD 6 EPOCH: 23 train_loss=0.69082 valid_loss=0.69042 valid_auc=0.53843 cum_return=176.77404 valid_uility_score=1060.64423\n",
      "FOLD 6 EPOCH: 24 train_loss=0.69089 valid_loss=0.69041 valid_auc=0.53701 cum_return=148.14188 valid_uility_score=825.40162\n",
      "FOLD 6 EPOCH: 25 train_loss=0.69089 valid_loss=0.69050 valid_auc=0.53784 cum_return=160.51971 valid_uility_score=963.11824\n",
      "FOLD 6 EPOCH: 26 train_loss=0.69085 valid_loss=0.69044 valid_auc=0.53733 cum_return=140.42309 valid_uility_score=842.53856\n",
      "FOLD 6 EPOCH: 27 train_loss=0.69086 valid_loss=0.69041 valid_auc=0.53718 cum_return=174.77545 valid_uility_score=1048.65272\n",
      "FOLD 6 EPOCH: 28 train_loss=0.69089 valid_loss=0.69041 valid_auc=0.53698 cum_return=157.01275 valid_uility_score=875.65947\n",
      "FOLD 6 EPOCH: 29 train_loss=0.69081 valid_loss=0.69032 valid_auc=0.53781 cum_return=162.08900 valid_uility_score=972.53402\n",
      "FOLD 7 EPOCH:  0 train_loss=0.69446 valid_loss=0.69229 valid_auc=0.52136 cum_return=-69.77611 valid_uility_score=-0.00000\n",
      "FOLD 7 EPOCH:  1 train_loss=0.69278 valid_loss=0.69203 valid_auc=0.52505 cum_return=-39.45242 valid_uility_score=-0.00000\n",
      "FOLD 7 EPOCH:  2 train_loss=0.69246 valid_loss=0.69164 valid_auc=0.53055 cum_return=-20.45441 valid_uility_score=-0.00000\n",
      "FOLD 7 EPOCH:  3 train_loss=0.69190 valid_loss=0.69086 valid_auc=0.53639 cum_return=18.68022 valid_uility_score=11.45599\n",
      "FOLD 7 EPOCH:  4 train_loss=0.69157 valid_loss=0.69068 valid_auc=0.53786 cum_return=35.17227 valid_uility_score=38.89601\n",
      "FOLD 7 EPOCH:  5 train_loss=0.69144 valid_loss=0.69055 valid_auc=0.53929 cum_return=46.12811 valid_uility_score=70.57985\n",
      "FOLD 7 EPOCH:  6 train_loss=0.69132 valid_loss=0.69063 valid_auc=0.53896 cum_return=32.83632 valid_uility_score=37.46499\n",
      "FOLD 7 EPOCH:  7 train_loss=0.69118 valid_loss=0.69052 valid_auc=0.53987 cum_return=54.49760 valid_uility_score=95.82945\n",
      "FOLD 7 EPOCH:  8 train_loss=0.69109 valid_loss=0.69051 valid_auc=0.53893 cum_return=55.87766 valid_uility_score=104.88497\n",
      "FOLD 7 EPOCH:  9 train_loss=0.69105 valid_loss=0.69067 valid_auc=0.53788 cum_return=14.35961 valid_uility_score=5.97340\n",
      "FOLD 7 EPOCH: 10 train_loss=0.69101 valid_loss=0.69057 valid_auc=0.53856 cum_return=70.48870 valid_uility_score=169.14846\n",
      "FOLD 7 EPOCH: 11 train_loss=0.69094 valid_loss=0.69056 valid_auc=0.53896 cum_return=41.64170 valid_uility_score=58.41931\n",
      "FOLD 7 EPOCH: 12 train_loss=0.69091 valid_loss=0.69058 valid_auc=0.53810 cum_return=56.22994 valid_uility_score=100.48931\n",
      "FOLD 7 EPOCH: 13 train_loss=0.69088 valid_loss=0.69045 valid_auc=0.53958 cum_return=70.66697 valid_uility_score=165.11942\n",
      "FOLD 7 EPOCH: 14 train_loss=0.69084 valid_loss=0.69063 valid_auc=0.53830 cum_return=83.84140 valid_uility_score=228.76015\n",
      "FOLD 7 EPOCH: 15 train_loss=0.69091 valid_loss=0.69053 valid_auc=0.54008 cum_return=63.89726 valid_uility_score=127.80926\n",
      "FOLD 7 EPOCH: 16 train_loss=0.69086 valid_loss=0.69053 valid_auc=0.53914 cum_return=67.78978 valid_uility_score=136.36682\n",
      "FOLD 7 EPOCH: 17 train_loss=0.69084 valid_loss=0.69060 valid_auc=0.53989 cum_return=75.29753 valid_uility_score=194.02742\n",
      "FOLD 7 EPOCH: 18 train_loss=0.69082 valid_loss=0.69066 valid_auc=0.53986 cum_return=53.51357 valid_uility_score=87.80465\n",
      "FOLD 7 EPOCH: 19 train_loss=0.69082 valid_loss=0.69038 valid_auc=0.53885 cum_return=55.09438 valid_uility_score=95.79458\n",
      "FOLD 7 EPOCH: 20 train_loss=0.69080 valid_loss=0.69050 valid_auc=0.53964 cum_return=60.67864 valid_uility_score=110.81567\n",
      "FOLD 7 EPOCH: 21 train_loss=0.69082 valid_loss=0.69071 valid_auc=0.53829 cum_return=64.00617 valid_uility_score=133.22068\n",
      "FOLD 7 EPOCH: 22 train_loss=0.69080 valid_loss=0.69047 valid_auc=0.53978 cum_return=52.76962 valid_uility_score=90.94109\n",
      "FOLD 7 EPOCH: 23 train_loss=0.69077 valid_loss=0.69061 valid_auc=0.53937 cum_return=44.63266 valid_uility_score=60.97168\n",
      "FOLD 7 EPOCH: 24 train_loss=0.69078 valid_loss=0.69064 valid_auc=0.53879 cum_return=71.06293 valid_uility_score=149.51087\n",
      "FOLD 7 EPOCH: 25 train_loss=0.69082 valid_loss=0.69033 valid_auc=0.53898 cum_return=54.56097 valid_uility_score=96.84867\n",
      "FOLD 7 EPOCH: 26 train_loss=0.69080 valid_loss=0.69037 valid_auc=0.54028 cum_return=84.09059 valid_uility_score=290.86175\n",
      "FOLD 7 EPOCH: 27 train_loss=0.69076 valid_loss=0.69071 valid_auc=0.53870 cum_return=23.83745 valid_uility_score=16.69711\n",
      "FOLD 7 EPOCH: 28 train_loss=0.69075 valid_loss=0.69069 valid_auc=0.53959 cum_return=38.15551 valid_uility_score=37.89168\n",
      "FOLD 7 EPOCH: 29 train_loss=0.69078 valid_loss=0.69063 valid_auc=0.53901 cum_return=65.48452 valid_uility_score=151.10000\n",
      "FOLD 8 EPOCH:  0 train_loss=0.69477 valid_loss=0.69206 valid_auc=0.52279 cum_return=23.94209 valid_uility_score=23.35196\n",
      "FOLD 8 EPOCH:  1 train_loss=0.69279 valid_loss=0.69164 valid_auc=0.52765 cum_return=43.12417 valid_uility_score=81.45811\n",
      "FOLD 8 EPOCH:  2 train_loss=0.69234 valid_loss=0.69094 valid_auc=0.53514 cum_return=104.97906 valid_uility_score=460.60150\n",
      "FOLD 8 EPOCH:  3 train_loss=0.69189 valid_loss=0.69066 valid_auc=0.53735 cum_return=122.74307 valid_uility_score=638.69164\n",
      "FOLD 8 EPOCH:  4 train_loss=0.69166 valid_loss=0.69057 valid_auc=0.53792 cum_return=122.50366 valid_uility_score=626.83313\n",
      "FOLD 8 EPOCH:  5 train_loss=0.69149 valid_loss=0.69056 valid_auc=0.53810 cum_return=114.30949 valid_uility_score=518.10393\n",
      "FOLD 8 EPOCH:  6 train_loss=0.69138 valid_loss=0.69044 valid_auc=0.53880 cum_return=143.95789 valid_uility_score=810.11717\n",
      "FOLD 8 EPOCH:  7 train_loss=0.69126 valid_loss=0.69027 valid_auc=0.53997 cum_return=149.89392 valid_uility_score=818.34763\n",
      "FOLD 8 EPOCH:  8 train_loss=0.69118 valid_loss=0.69019 valid_auc=0.54029 cum_return=115.59190 valid_uility_score=551.67455\n",
      "FOLD 8 EPOCH:  9 train_loss=0.69111 valid_loss=0.69001 valid_auc=0.54130 cum_return=126.84897 valid_uility_score=675.99568\n",
      "FOLD 8 EPOCH: 10 train_loss=0.69112 valid_loss=0.69005 valid_auc=0.54065 cum_return=137.74173 valid_uility_score=810.02524\n",
      "FOLD 8 EPOCH: 11 train_loss=0.69102 valid_loss=0.68989 valid_auc=0.54231 cum_return=120.99123 valid_uility_score=712.82688\n",
      "FOLD 8 EPOCH: 12 train_loss=0.69103 valid_loss=0.68996 valid_auc=0.54324 cum_return=144.72134 valid_uility_score=868.32804\n",
      "FOLD 8 EPOCH: 13 train_loss=0.69107 valid_loss=0.69003 valid_auc=0.54060 cum_return=149.17591 valid_uility_score=874.42571\n",
      "FOLD 8 EPOCH: 14 train_loss=0.69100 valid_loss=0.68987 valid_auc=0.54192 cum_return=130.95512 valid_uility_score=726.95807\n",
      "FOLD 8 EPOCH: 15 train_loss=0.69099 valid_loss=0.68998 valid_auc=0.54295 cum_return=132.98535 valid_uility_score=746.18603\n",
      "FOLD 8 EPOCH: 16 train_loss=0.69095 valid_loss=0.68970 valid_auc=0.54353 cum_return=123.57359 valid_uility_score=654.83587\n",
      "FOLD 8 EPOCH: 17 train_loss=0.69096 valid_loss=0.68972 valid_auc=0.54262 cum_return=126.84615 valid_uility_score=725.88929\n",
      "FOLD 8 EPOCH: 18 train_loss=0.69096 valid_loss=0.68971 valid_auc=0.54323 cum_return=121.51423 valid_uility_score=648.31656\n",
      "FOLD 8 EPOCH: 19 train_loss=0.69094 valid_loss=0.68981 valid_auc=0.54349 cum_return=131.83136 valid_uility_score=731.44176\n",
      "FOLD 8 EPOCH: 20 train_loss=0.69095 valid_loss=0.68968 valid_auc=0.54288 cum_return=130.55218 valid_uility_score=675.11798\n",
      "FOLD 8 EPOCH: 21 train_loss=0.69091 valid_loss=0.68987 valid_auc=0.54334 cum_return=124.03238 valid_uility_score=653.67496\n",
      "FOLD 8 EPOCH: 22 train_loss=0.69091 valid_loss=0.68987 valid_auc=0.54269 cum_return=131.70539 valid_uility_score=790.23235\n",
      "FOLD 8 EPOCH: 23 train_loss=0.69092 valid_loss=0.68975 valid_auc=0.54327 cum_return=115.93608 valid_uility_score=556.09161\n",
      "FOLD 8 EPOCH: 24 train_loss=0.69090 valid_loss=0.68956 valid_auc=0.54465 cum_return=135.83169 valid_uility_score=760.77287\n",
      "FOLD 8 EPOCH: 25 train_loss=0.69094 valid_loss=0.68982 valid_auc=0.54325 cum_return=125.78543 valid_uility_score=743.27667\n",
      "FOLD 8 EPOCH: 26 train_loss=0.69091 valid_loss=0.68972 valid_auc=0.54214 cum_return=117.48843 valid_uility_score=584.84083\n",
      "FOLD 8 EPOCH: 27 train_loss=0.69087 valid_loss=0.68970 valid_auc=0.54421 cum_return=135.89479 valid_uility_score=815.36874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 8 EPOCH: 28 train_loss=0.69091 valid_loss=0.68987 valid_auc=0.54372 cum_return=142.50387 valid_uility_score=809.65577\n",
      "FOLD 8 EPOCH: 29 train_loss=0.69089 valid_loss=0.68976 valid_auc=0.54364 cum_return=133.37518 valid_uility_score=715.91969\n",
      "FOLD 9 EPOCH:  0 train_loss=0.69463 valid_loss=0.69221 valid_auc=0.51974 cum_return=161.69425 valid_uility_score=735.56642\n",
      "FOLD 9 EPOCH:  1 train_loss=0.69281 valid_loss=0.69173 valid_auc=0.52590 cum_return=95.94807 valid_uility_score=411.64363\n",
      "FOLD 9 EPOCH:  2 train_loss=0.69239 valid_loss=0.69092 valid_auc=0.53609 cum_return=149.57623 valid_uility_score=897.45738\n",
      "FOLD 9 EPOCH:  3 train_loss=0.69189 valid_loss=0.69026 valid_auc=0.54229 cum_return=220.48709 valid_uility_score=1322.92252\n",
      "FOLD 9 EPOCH:  4 train_loss=0.69165 valid_loss=0.69031 valid_auc=0.54332 cum_return=247.39677 valid_uility_score=1484.38061\n",
      "FOLD 9 EPOCH:  5 train_loss=0.69155 valid_loss=0.69010 valid_auc=0.54504 cum_return=252.55104 valid_uility_score=1515.30625\n",
      "FOLD 9 EPOCH:  6 train_loss=0.69136 valid_loss=0.68983 valid_auc=0.54550 cum_return=239.03756 valid_uility_score=1434.22539\n",
      "FOLD 9 EPOCH:  7 train_loss=0.69132 valid_loss=0.68988 valid_auc=0.54592 cum_return=253.33144 valid_uility_score=1519.98866\n",
      "FOLD 9 EPOCH:  8 train_loss=0.69126 valid_loss=0.68959 valid_auc=0.54669 cum_return=222.08898 valid_uility_score=1332.53391\n",
      "FOLD 9 EPOCH:  9 train_loss=0.69118 valid_loss=0.68956 valid_auc=0.54858 cum_return=255.81504 valid_uility_score=1534.89024\n",
      "FOLD 9 EPOCH: 10 train_loss=0.69110 valid_loss=0.68943 valid_auc=0.54870 cum_return=259.33724 valid_uility_score=1556.02345\n",
      "FOLD 9 EPOCH: 11 train_loss=0.69115 valid_loss=0.68957 valid_auc=0.54750 cum_return=234.81066 valid_uility_score=1408.86397\n",
      "FOLD 9 EPOCH: 12 train_loss=0.69107 valid_loss=0.68947 valid_auc=0.54887 cum_return=222.69256 valid_uility_score=1336.15533\n",
      "FOLD 9 EPOCH: 13 train_loss=0.69112 valid_loss=0.68951 valid_auc=0.54853 cum_return=230.14354 valid_uility_score=1380.86125\n",
      "FOLD 9 EPOCH: 14 train_loss=0.69106 valid_loss=0.68979 valid_auc=0.54800 cum_return=241.05186 valid_uility_score=1446.31118\n",
      "FOLD 9 EPOCH: 15 train_loss=0.69104 valid_loss=0.68948 valid_auc=0.54653 cum_return=219.12606 valid_uility_score=1314.75639\n",
      "FOLD 9 EPOCH: 16 train_loss=0.69103 valid_loss=0.68945 valid_auc=0.54751 cum_return=241.14136 valid_uility_score=1446.84815\n",
      "FOLD 9 EPOCH: 17 train_loss=0.69100 valid_loss=0.68955 valid_auc=0.54743 cum_return=226.18316 valid_uility_score=1357.09897\n",
      "FOLD 9 EPOCH: 18 train_loss=0.69098 valid_loss=0.68973 valid_auc=0.54815 cum_return=241.21796 valid_uility_score=1447.30779\n",
      "FOLD 9 EPOCH: 19 train_loss=0.69092 valid_loss=0.68939 valid_auc=0.54781 cum_return=254.85094 valid_uility_score=1529.10567\n",
      "FOLD 9 EPOCH: 20 train_loss=0.69092 valid_loss=0.68961 valid_auc=0.54891 cum_return=232.05290 valid_uility_score=1392.31742\n",
      "FOLD 9 EPOCH: 21 train_loss=0.69094 valid_loss=0.68965 valid_auc=0.54714 cum_return=204.84936 valid_uility_score=1229.09618\n",
      "FOLD 9 EPOCH: 22 train_loss=0.69094 valid_loss=0.68965 valid_auc=0.55026 cum_return=259.42970 valid_uility_score=1556.57819\n",
      "FOLD 9 EPOCH: 23 train_loss=0.69099 valid_loss=0.68960 valid_auc=0.54571 cum_return=204.10253 valid_uility_score=1224.61518\n",
      "FOLD 9 EPOCH: 24 train_loss=0.69092 valid_loss=0.68974 valid_auc=0.54770 cum_return=216.60620 valid_uility_score=1299.63719\n",
      "FOLD 9 EPOCH: 25 train_loss=0.69093 valid_loss=0.68946 valid_auc=0.54872 cum_return=177.03326 valid_uility_score=1062.19954\n",
      "FOLD 9 EPOCH: 26 train_loss=0.69091 valid_loss=0.68912 valid_auc=0.54923 cum_return=209.83914 valid_uility_score=1259.03485\n",
      "FOLD 9 EPOCH: 27 train_loss=0.69092 valid_loss=0.68927 valid_auc=0.54848 cum_return=222.44926 valid_uility_score=1334.69558\n",
      "FOLD 9 EPOCH: 28 train_loss=0.69091 valid_loss=0.68947 valid_auc=0.54821 cum_return=224.03473 valid_uility_score=1344.20837\n",
      "FOLD 9 EPOCH: 29 train_loss=0.69095 valid_loss=0.68957 valid_auc=0.54826 cum_return=222.23096 valid_uility_score=1333.38578\n"
     ]
    }
   ],
   "source": [
    "TRAIN_MODE = True\n",
    "EPOCHS = 30\n",
    "DEVICE = \"cuda:0\"\n",
    "BATCH_SIZE = 10240\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "K = 10\n",
    "\n",
    "\n",
    "if TRAIN_MODE:\n",
    "    for i in range(K):\n",
    "        train_feature, train_label, valid_feature, valid_label, df_valid =  Get_K_Fold_Data_(i, K,  DATA, fea_cols, lab_cols)\n",
    "        train_dataloader = dataloader(train_feature, train_label, BATCH_SIZE=BATCH_SIZE, shuffle=True)\n",
    "        valid_dataloader = dataloader(valid_feature, valid_label, BATCH_SIZE=BATCH_SIZE, shuffle=False)\n",
    "        torch.cuda.empty_cache()\n",
    "        model = Resnet([48, 48, 32], [132, 131], 6)\n",
    "        \n",
    "        model.encoder_decoder.load_state_dict(encoder_decoder.state_dict())\n",
    "        model.encoder_decoder.encoder.Gaussiannoise.on = False\n",
    "        model.encoder_decoder.requires_grad_(False)\n",
    "\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        for epo in range(EPOCHS):\n",
    "            train_loss = train_fn_(model, opt, train_dataloader, loss_fn, DEVICE, PcA)\n",
    "            valid_pred = inference_fn_(model, valid_dataloader, DEVICE, PcA)\n",
    "            valid_loss = float((loss_fn(torch.FloatTensor(valid_pred), torch.FloatTensor(valid_label))).detach().cpu().numpy())\n",
    "            valid_auc = roc_auc_score(valid_label, torch.sigmoid(torch.FloatTensor(valid_pred)).detach().cpu().numpy())\n",
    "            #valid_pred = np.median(torch.sigmoid(torch.FloatTensor(valid_pred)).detach().cpu().numpy(), axis=1)\n",
    "            valid_pred = torch.sigmoid(torch.FloatTensor(valid_pred)[:, 0]).detach().cpu().numpy()\n",
    "            valid_pred = np.where(valid_pred >= 0.5, 1, 0).astype(int)\n",
    "            valid_u_score = utility_score_bincount(date=df_valid.date.values, weight=df_valid.weight.values,\n",
    "                                                   resp=df_valid.resp.values, action=valid_pred)\n",
    "            \n",
    "            cum_return = sum(df_valid.resp.values * valid_pred * df_valid.weight.values)\n",
    "            print(f\"FOLD{i:2} EPOCH:{epo:3} train_loss={train_loss:.5f} valid_loss={valid_loss:.5f} valid_auc={valid_auc:.5f} cum_return={cum_return:.5f} valid_uility_score={valid_u_score:.5f}\")\n",
    "        \n",
    "        model.eval()\n",
    "        model.to(\"cpu\")\n",
    "        Resnet_Save_Path = \"../model_02_18/Resnet_02_18_new_feature_v{}.pth\".format(i)\n",
    "        torch.save(model.state_dict(), Resnet_Save_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
